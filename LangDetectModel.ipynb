{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUYnJVTUlZU0",
        "outputId": "853f76d2-1ac2-4c21-e635-53d787bfbdbe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Label Mapping: {'te': 0, 'kn': 1, 'ml': 2, 'ta': 3, 'hi': 4, 'mr': 5, 'gu': 6, 'bn': 7, 'pa': 8, 'ur': 9, 'or': 10, 'sd': 11}\n",
            "Training set size: 4199\n",
            "Test set size: 1800\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertForSequenceClassification\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('Big_Dataset.csv')\n",
        "\n",
        "# Fix column name if necessary (to ensure consistency)\n",
        "if 'Langid' in data.columns:\n",
        "    data.rename(columns={'Langid': 'Langid'}, inplace=True)\n",
        "\n",
        "# Define features and labels\n",
        "X = data['Sentences'].dropna()  # Sentences/Texts\n",
        "y = data['Langid'].dropna()  # Language labels (ensure correct column name)\n",
        "\n",
        "# Split into train and validation sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# Create a mapping of unique language codes to integer labels\n",
        "label_map = {label: idx for idx, label in enumerate(y.unique())}\n",
        "\n",
        "# Convert labels to numerical format\n",
        "y_train_encoded = y_train.map(label_map)\n",
        "y_test_encoded = y_test.map(label_map)\n",
        "\n",
        "# Load the pretrained multilingual BERT model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", num_labels=len(label_map)\n",
        ")\n",
        "\n",
        "# Print label mapping for reference\n",
        "print(\"Label Mapping:\", label_map)\n",
        "\n",
        "# Check the size of the training and test datasets\n",
        "print(f\"Training set size: {X_train.shape[0]}\")\n",
        "print(f\"Test set size: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QbdSl9gilh6g"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "iw23D3KAl3QO"
      },
      "outputs": [],
      "source": [
        "# 1. Tokenization\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mZ8CIyqTl6g8"
      },
      "outputs": [],
      "source": [
        "# Tokenize the sentences (both train and test sets)\n",
        "train_encodings = tokenizer(list(X_train), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "test_encodings = tokenizer(list(X_test), padding=True, truncation=True, max_length=128, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "arzVu2XQmCdK"
      },
      "outputs": [],
      "source": [
        "# 2. Prepare DataLoader\n",
        "# Convert the labels into tensors\n",
        "train_labels = torch.tensor(y_train_encoded.values)\n",
        "test_labels = torch.tensor(y_test_encoded.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XvjGo3xtmIEv"
      },
      "outputs": [],
      "source": [
        "# Create TensorDataset for both training and test datasets\n",
        "train_dataset = TensorDataset(train_encodings['input_ids'], train_encodings['attention_mask'], train_labels)\n",
        "test_dataset = TensorDataset(test_encodings['input_ids'], test_encodings['attention_mask'], test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Hf4y_1XcmM3G"
      },
      "outputs": [],
      "source": [
        "# Create DataLoaders for batching\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_OTD0QbmRUB",
        "outputId": "dc073047-34e6-42b9-8285-16e7b5c4e69e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\omray\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# 3. Set up the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlbAGmnxmUBu",
        "outputId": "a058a625-6007-403b-ca53-fe0081df41db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=12, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. Training loop\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "3nvCwYzJmXS4"
      },
      "outputs": [],
      "source": [
        "epochs = 30\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y2z0IH2mgRF",
        "outputId": "4b32b39a-aa7b-47e9-9857-8ebf78f2f768"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/30:   1%|          | 3/263 [00:27<39:04,  9.02s/it, loss=2.47]"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Wrap train_loader with tqdm to show progress\n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", leave=True)\n",
        "\n",
        "    for batch in progress_bar:\n",
        "        # Get the inputs and labels\n",
        "        input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = outputs.loss\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Backward pass (compute gradients)\n",
        "        loss.backward()\n",
        "\n",
        "        # Update model parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update tqdm progress bar with current loss\n",
        "        progress_bar.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Training loss: {avg_train_loss}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmcYhVBvm1ZU"
      },
      "outputs": [],
      "source": [
        "# 5. Save the model\n",
        "model.save_pretrained(\"./language_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FLNSGzpES1D",
        "outputId": "a5be1ca1-335f-4611-9503-ec4dc661abb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('./language_model/tokenizer_config.json',\n",
              " './language_model/special_tokens_map.json',\n",
              " './language_model/vocab.txt',\n",
              " './language_model/added_tokens.json')"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.save_pretrained(\"./language_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QueJ8zY31yN7",
        "outputId": "6fec7d88-1af7-43ea-da65-aba89a9bcb46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to predicted_language_codes.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Load the trained model and tokenizer\n",
        "model_path = \"./language_model\"  # Path where the model is saved\n",
        "model = BertForSequenceClassification.from_pretrained(model_path)\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "# Move model to device (GPU if available)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "model.eval()  # Set model to evaluation mode\n",
        "\n",
        "# Function to predict language code\n",
        "def predict_language(sentence):\n",
        "    # Tokenize the input sentence\n",
        "    encoding = tokenizer(sentence, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n",
        "\n",
        "    # Move input tensors to the correct device\n",
        "    input_ids = encoding[\"input_ids\"].to(device)\n",
        "    attention_mask = encoding[\"attention_mask\"].to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "\n",
        "    # Get predicted label\n",
        "    predicted_label_id = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    # Convert back to language code using label_map\n",
        "    predicted_language = [lang for lang, idx in label_map.items() if idx == predicted_label_id][0]\n",
        "\n",
        "    return predicted_language\n",
        "\n",
        "# Predict for all test sentences\n",
        "predicted_languages = [predict_language(sentence) for sentence in X_test]\n",
        "\n",
        "# Create a DataFrame with actual and predicted language codes\n",
        "output_df = pd.DataFrame({\n",
        "    'Sentence': X_test.values,             # Original sentence\n",
        "    'Actual Language Code': y_test.values,  # Original language label\n",
        "    'Predicted Language Code': predicted_languages  # Predicted language code\n",
        "})\n",
        "\n",
        "# Save to CSV file\n",
        "output_file = \"predicted_language_codes.csv\"\n",
        "output_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2aApBRd0UI4",
        "outputId": "a1fd09ec-0120-4ed4-e53a-9d3615d5ee7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(580, 2)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHr9ApGy01Dx",
        "outputId": "ed681e53-9bc1-4b69-9585-8328468263c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 97.70%\n"
          ]
        }
      ],
      "source": [
        "#Calculate accuracy score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy = accuracy_score(y_test, predicted_languages)\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vf8JAsw5BCJ-"
      },
      "outputs": [],
      "source": [
        "from transformers import BertForSequenceClassification, BertTokenizer\n",
        "import torch\n",
        "\n",
        "# Path to the saved model and tokenizer\n",
        "model_pathe = '/content/language_model'\n",
        "tokenizer_pathe= '/content/language_model'\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = BertForSequenceClassification.from_pretrained(model_pathe)\n",
        "tokenizer = BertTokenizer.from_pretrained(tokenizer_pathe)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbvxQyQsBCNY"
      },
      "outputs": [],
      "source": [
        "input_text= \"kozhikkodu bas marinju niravadhi perkku parukku; oralude nila gurutharam, bas uyarthaan shramam...\"\n",
        "# Tokenize the input text\n",
        "inputs = tokenizer(input_text, return_tensors=\"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9y7LO3_1BCRC",
        "outputId": "9cb7c260-4570-44b8-e5f5-565f17fe55b5"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Perform inference (turn off gradients for inference)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m      3\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get the logits (raw predictions)\u001b[39;00m\n",
            "\u001b[1;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ],
      "source": [
        "# Perform inference (turn off gradients for inference)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "\n",
        "# Get the logits (raw predictions)\n",
        "logits = outputs.logits\n",
        "\n",
        "# If it's a classification task, you can get the predicted class\n",
        "predicted_class = torch.argmax(logits, dim=-1)\n",
        "\n",
        "# Print the predicted class (assuming you have class labels corresponding to languages)\n",
        "# You will need to map the predicted class index to its corresponding language\n",
        "languages = ['ml','hi','mr','gu','ta','te','or','bn','ur','sn','kn']  # Example language labels\n",
        "predicted_language = languages[predicted_class.item()]\n",
        "\n",
        "print(f\"Predicted language: {predicted_language}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HonPfKAwBCUm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwnVUIXxBCb0"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu6lu6jHBCfR"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
